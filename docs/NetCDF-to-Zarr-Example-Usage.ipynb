{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43fb257b-e819-44ae-b5c9-3c619a3dd065",
   "metadata": {},
   "source": [
    "# NetCDF-to-Zarr service example usage\n",
    "\n",
    "The scope of this notebook is to demonstrate example requests that use the NetCDF-to-Zarr Harmony backend service via `harmony-py`. Once each request has completed, the output will be accessed in-region from S3.\n",
    "\n",
    "To run the cells that access the data in S3, this notebook will need to be run from within the AWS `us-west-2` region. One way of accomplishing this is to run the notebook within the [Openscapes 2i2c Jupyter Hub](https://openscapes.2i2c.cloud/hub).\n",
    "\n",
    "### Authentication prerequisites:\n",
    "\n",
    "The `harmony.Client` class will attempt to use credentials from a local `.netrc` file, located in the home directory of the filesystem where this notebook is running. This will need to contain entries for Earthdata Login (at minimum for the UAT environment):\n",
    "\n",
    "```\n",
    "machine urs.earthdata.nasa.gov\n",
    "    login <prod_edl_username>\n",
    "    password <prod_edl_password>\n",
    "\n",
    "machine uat.urs.earthdata.nasa.gov\n",
    "    login <uat_edl_username>\n",
    "    password <uat_edl_password>\n",
    "```\n",
    "\n",
    "### Importing required packages:\n",
    "\n",
    "The cell below imports classes and functions from various Python packages, these packages include:\n",
    "\n",
    "* `harmony-py`: A package that allows for easy, interaction with the Harmony API that can be written directly in Python.\n",
    "* `pprint`: A lightweight package that can print data structures with indentation to aid in their visual inspection.\n",
    "* `s3fs`: A package that enables interactions with items stored in AWS S3.\n",
    "* `matplotlib`: A package used extensively for plotting data in Python.\n",
    "* `xarray`: A package that can read and write data stored in a number of formats, including NetCDF-4 and Zarr.\n",
    "\n",
    "Further packages required by the Python environment running this notebook include:\n",
    "\n",
    "* `netCDF4`: A package primarily used for interacting with NetCDF-4 files. This package is not explicitly imported below, but `xarray` requires this to read a Zarr store.\n",
    "* `zarr`: A package that interacts with Zarr stores. Again, this package is not explicitly imported below, but `xarray` requires it to read a Zarr store.\n",
    "\n",
    "The packages in both lists above should be installed in the environment in which this notebook is running, prior to starting the notebook. They are included by default in the Openscapes 2i2c Jupyter Hub as part of the Corn development environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb2c839-75a7-4f37-a006-2f7a792df4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from harmony import Client, Collection, Environment, LinkType, Request\n",
    "from pprint import pprint\n",
    "from s3fs import S3FileSystem\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3144916f-aae1-462e-8e12-56d91738cc52",
   "metadata": {},
   "source": [
    "### Setting up a Harmony client:\n",
    "\n",
    "In this notebook, requests will be made against test data in the UAT environment. First an instance of the `harmony.Client` class is created, which simplifies the interactions with the Harmony API, including request submission and retrieval of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6264d5b-b78a-41a3-9f52-a027088413b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "harmony_client = Client(env=Environment.UAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34279907-fef6-4151-a61e-757084060cb0",
   "metadata": {},
   "source": [
    "### Setting up an S3 connection:\n",
    "\n",
    "The `s3fs.S3FileSystem` class creates a connection to S3, such that typical filesystem commands can be used against the contents of S3 (see documentation [here](https://s3fs.readthedocs.io/en/latest/)). The same instance will be used to interact with the outputs from the requests in the notebook below. The credentials necessary to access Harmony outputs stored in AWS S3 can be generated using the `harmony.Client` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21a012c-5575-4f62-bb76-984a3065afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_credentials = harmony_client.aws_credentials()\n",
    "\n",
    "s3_fs = S3FileSystem(key=s3_credentials['aws_access_key_id'],\n",
    "                     secret=s3_credentials['aws_secret_access_key'],\n",
    "                     token=s3_credentials['aws_session_token'],\n",
    "                     client_kwargs={'region_name':'us-west-2'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d047de5e-dfa3-4a43-a59b-74b53f4577b7",
   "metadata": {},
   "source": [
    "## Converting a single granule:\n",
    "\n",
    "The request below will make a request against the [Harmony Example L2 Data collection](https://cmr.uat.earthdata.nasa.gov/search/concepts/C1233860183-EEDTEST.html). Each granule is a small NetCDF-4 file, with 4 science variables and swath dimension variables.\n",
    "\n",
    "First, a request is constructed via the `harmony.Request` class. In this request only the data collection, output format and number of granules will be specified. This request will create a Zarr store from the first granule in the collection.\n",
    "\n",
    "The request will then be submitted to the Harmony API using the `harmony.Client` object, and URLs for the results can be retrieved once the job is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14429e55-e058-4872-8d0e-f70ff55da735",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_l2_collection = Collection(id='C1233860183-EEDTEST')\n",
    "\n",
    "# Specify a request to create Zarr output for one granule in the collection:\n",
    "single_granule_request = Request(collection=example_l2_collection, format='application/x-zarr',\n",
    "                                 granule_id='G1233860549-EEDTEST')\n",
    "\n",
    "# Submit the request and wait for it to complete:\n",
    "single_granule_job_id = harmony_client.submit(single_granule_request)\n",
    "harmony_client.wait_for_processing(single_granule_job_id, show_progress=True)\n",
    "\n",
    "# Filter the results to only include links to resources in S3:\n",
    "single_granule_result_urls = list(harmony_client.result_urls(single_granule_job_id, link_type=LinkType.s3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f1f4a9-9c7f-4faa-94d2-3778c8af122c",
   "metadata": {},
   "source": [
    "### Reading calibrated data:\n",
    "\n",
    "By default, when reading data from a Zarr store, `xarray.open_zarr` will apply the `add_offset`, `scale_factor` and `_FillValue` metadata attributes to the array values of a variable, if they are present.\n",
    "\n",
    "In the example request, the raw data for `/blue_var` contain the following metadata attributes:\n",
    "\n",
    "* `add_offset = 210`\n",
    "* `scale_factor = 2`\n",
    "* `_FillValue = 0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424ba0c5-8583-41b0-8711-74ca097df8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_dataset = xr.open_zarr(s3_fs.get_mapper(single_granule_result_urls[0]))\n",
    "calibrated_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d88bf40-fea2-4ad0-9e36-9ec3f6e46380",
   "metadata": {},
   "source": [
    "### Inspecting the calibrated metadata attributes:\n",
    "\n",
    "The dictionary below contains all the metadata attributes available for the `/blue_var` in the Zarr store when using the default options for reading the data. This variable only contains the `scale_factor`, `add_offset` and `_FillValue` metadata attributes, all of which are applied when `xarray` reads the Zarr store and automatically masks and scales the variable array values. These metadata attributes are therefore not retained after they have been applied to the data and as such the dictionary below will be empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62392c20-1b98-46c3-bd69-e8599c6fc3e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "calibrated_dataset.blue_var.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781ca0c6-9581-4578-a7fe-7bf96fc9b217",
   "metadata": {},
   "source": [
    "### Plotting calibrated variable values:\n",
    "\n",
    "As noted, the `/blue_var` variable has the `scale_factor`, `add_offset` and `_FillValue` metadata attributes in the raw data. Plotting the data for this variable via `xarray` show that these values have been applied to the data by default. The data in `/blue_var` are masked, such that fill values are present at all points in the array covering land, in this case the continent of Africa. As `xarray` has already applied the stored fill value to the array, Africa is plotted in white, denoting a region where the array contains recognised fill values.\n",
    "\n",
    "Also note the scale of the data ranging from 212 to 240. Because the raw data are integers, and `_FillValue = 0`, the lowest possible raw data value is 1, when scaled this becomes 212."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce5cc5c-e280-4ed0-84aa-552651ae15fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = calibrated_dataset.blue_var.plot(x='lon', y='lat', cmap=plt.cm.coolwarm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc96742-1c7a-4593-898b-8aa27549336f",
   "metadata": {},
   "source": [
    "### Reading raw data:\n",
    "\n",
    "The raw array values for variables can be read using `xarray.open_zarr` by specifying the `mask_and_scale` keyword argument to be `False` (it is `True` by default). This is shown below.\n",
    "\n",
    "Note: because these attributes are not automatically applied to the values, they will be persisted as attributes in the `.attrs` dictionary of the relevant variable (e.g., `raw_dataset.blue_var.attrs`). These attributes will also now be shown in the table displayed below. Clicking on the metadata icon, 📄, for a variable will expand its entry in the table to show all available metadata attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd91ce56-7f7b-4167-ae37-d4d5a9c2a319",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = xr.open_zarr(s3_fs.get_mapper(single_granule_result_urls[0]), mask_and_scale=False)\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28b98e3-e1d2-4357-902a-6f128b9c3c78",
   "metadata": {},
   "source": [
    "### Inspecting the raw metadata attributes:\n",
    "\n",
    "The dictionary below contains the available metadata attributes for the `/blue_var` in the Zarr store, when specifying that the data should _not_ automatically apply the `scale_factor`, `add_offset` and `_FillValue` attributes. All three of these metadata attributes therefore remain available in the `attrs` dictionary below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3120525c-d110-4ba5-bf12-d628143a96ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset.blue_var.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483e75f8-3090-44ba-bcaf-c19be69b7bc4",
   "metadata": {},
   "source": [
    "### Plotting raw variable values:\n",
    "\n",
    "The plot below shows the values stored by `xarray` when not automatically calibrating or masking the data using the available metadata attributes. Note the continent of Africa now has array values of 0, which corresponds to the `_FillValue` metadata attribute value, and these are not automatically recognised as fill values by `xarray`. Also note the scale of the data ranging from 0 to 15, which is the full range of the raw data values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f191c233-faa1-4215-b8c5-0d1d4cef59df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = raw_dataset.blue_var.plot(x='lon', y='lat', cmap=plt.cm.coolwarm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24443120-74a8-489c-88d8-3dd9641878a5",
   "metadata": {},
   "source": [
    "## Temporal Aggregation:\n",
    "\n",
    "The NetCDF-to-Zarr service can aggregate data along a temporal dimension, such that multiple input NetCDF-4 files are combined into a single Zarr store. This is the default behaviour when requesting multiple NetCDF-4 input files within this same request. To produce an individual Zarr store for each input NetCDF-4 file instead, the request must specify `concatenate=False`. \n",
    "\n",
    "The temporal aggregation operation assumes that all input files are gridded (spatially and temporally), and that the spatial extents for all input NetCDF-4 files are the same. The variables being aggregated must have an associated temporal dimension that refers to the temporal grid values stored within a 1-D variable. This 1-D variable must have a `units` metadata attribute that complies with the [CF-Conventions](https://cfconventions.org/Data/cf-conventions/cf-conventions-1.9/cf-conventions.html#time-coordinate).\n",
    "\n",
    "The example request below will use data from the Global Precipitation Measurement (GPM) mission Integrated Multi-satellitE Retrievals for GPM (IMERG) half-hourly collection. Each granule represents a single half hour increment of time, with data stored in a three dimensional grid. The figure below shows an example GPM/IMERG granule as viewed within Panoply:\n",
    "\n",
    "<center><img src='images/GPM_IMERG_Panoply.png'></center>\n",
    "\n",
    "**Figure 1:** A GPM/IMERG NetCDF-4 file displayed in Panoply.\n",
    "\n",
    "The grid dimensions for each gridded GPM/IMERG variable are $time$, $longitude$ and $latitude$, with the horizontal spatial coordinates providing whole-Earth coverage (0.1 degree resolution), while the $time$ dimension contains only a single value.\n",
    "\n",
    "The figure below shows how the request takes 6 input NetCDF-4 files, whose grids have dimensions (1, 3600, 1800), and produces a single Zarr store with grid dimensions (6, 3600, 1800).\n",
    "\n",
    "<center><img src='images/stacked_output.png'></center>\n",
    "\n",
    "**Figure 2:** Left: A gridded science variable as represented in six separate NetCDF-4 input GPM/IMERG granules. These have dimensions (1, 3600, 1800). Right: The stacked variable as saved in the output Zarr store. This has dimensions (6, 3600, 1800).\n",
    "\n",
    "The temporal aggregation will always produce a regular grid. If there are gaps in data coverage, then the temporal dimension will include a value for the missing data, but that slice will be populated with fill values.\n",
    "\n",
    "### The temporal aggregation request:\n",
    "\n",
    "The request below uses a temporal range to filter the GPM/IMERG collection down to 6 consecutive granules. Each of these granules corresponds to a NetCDF-4 file, each of which has a different timestamp stored in the `/Grid/time` variable. The 6 input files have consecutive time values, such that the aggregated output will form a grid with a time dimension of length 6 values, all half an hour apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8207d019-aefc-43c6-ab98-d6d5fbbf9d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpm_imerg = Collection(id='C1225808238-GES_DISC')\n",
    "\n",
    "# Specify a request to create Zarr output for six granules from the GPM/IMERG collection in a specific temporal range:\n",
    "temporal_aggregation_request = Request(collection=gpm_imerg,\n",
    "                                       temporal={'start': datetime(2020,1, 1),\n",
    "                                                 'stop': datetime(2020, 1, 1, 2, 59)},\n",
    "                                       format='application/x-zarr')\n",
    "\n",
    "# Submit the request and wait for it to complete:\n",
    "temporal_aggregation_job_id = harmony_client.submit(temporal_aggregation_request)\n",
    "harmony_client.wait_for_processing(temporal_aggregation_job_id, show_progress=True)\n",
    "\n",
    "# Filter the results to only include links to resources in S3:\n",
    "temporal_aggregation_result_urls = list(harmony_client.result_urls(temporal_aggregation_job_id, link_type=LinkType.s3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53fd37a-665c-47fc-96e2-6f23b040b13d",
   "metadata": {},
   "source": [
    "### Accessing temporally aggregated results:\n",
    "\n",
    "The following cell uses `xarray` to read the aggregated results. The variables are all contained in the `/Grid` group, so `xarray.open_zarr` specifies this group via the `group` keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3354630c-16df-4f97-b3bf-2afd76a8a905",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_dataset = xr.open_zarr(s3_fs.get_mapper(temporal_aggregation_result_urls[0]), group='/Grid', decode_cf=True)\n",
    "aggregated_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e555f32-0f86-4d15-8653-5117565b0d6c",
   "metadata": {},
   "source": [
    "### Plotting the data:\n",
    "\n",
    "In the cell below, `xarray` plotting functionality is used to plot each of the temporal slices of data in the aggregated `/Grid/precipitationCal` variable. The output will display 6 panels in two columns. Each column corresponds to a slice in the 3-dimensional array, with the corresponding time value displayed in the title of the panel. The spatial region has been specified by `xlim` and `ylim`, zooming in on a 20° x 20° region of the southern Pacific Ocean, such that it is possible to visually compare the output at each time, showing an evolution between the array slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d4aac8-05ee-4f56-a2cd-f1072aac15c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_dataset.precipitationCal.plot(x='lon', y='lat', col='time', col_wrap=2, size=8, vmax=40,\n",
    "                                         cmap=plt.cm.coolwarm, xlim=[-169, -149], ylim=[-47, -27])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab91789-01e9-44e4-98fc-376d6e32cc65",
   "metadata": {},
   "source": [
    "### Should I temporally aggregate my collection?\n",
    "\n",
    "Concatenation into a single Zarr store is now the default behaviour. To retrieve a single Zarr store per input NetCDF-4 granule, the `concatenate=false` query parameter is required.\n",
    "\n",
    "When to _not_ concatenate:\n",
    "\n",
    "* Different input NetCDF-4 files cover different spatial extents (a future extension).\n",
    "* The input NetCDF-4 files do not include time as a grid dimension, e.g.: $(longitude, latitude)$ rather than $(time, longitude, latitude)$.\n",
    "* Large input data volume (either many or very large input NetCDF-4 files)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
